{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ed6b54-f74e-4341-bf36-10d5cc01a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b95bf1",
   "metadata": {},
   "source": [
    "### 1. Phoneme Dataset\n",
    "Load the phoneme dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c9a895-9863-4a10-9c4b-fcc5dcb21283",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/phoneme.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/phoneme.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m pd\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mchained_assignment \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# Just gonna pretend we're not gettting the error...\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m observation \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\William\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/phoneme.csv'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data = pd.read_csv('/phoneme.csv')\n",
    "\n",
    "pd.options.mode.chained_assignment = None # Just gonna pretend we're not gettting the error...\n",
    "for observation in range(len(data)):\n",
    "    data['speaker'][observation] = data['speaker'][observation][0:5]\n",
    "\n",
    "grouped = [y for _, y in data.groupby(data['speaker'])]\n",
    "test = grouped[0].loc[:, data.columns.drop(['speaker','row.names'])]\n",
    "train = grouped[1].loc[:, data.columns.drop(['speaker', 'row.names'])]\n",
    "# Split the dataset into a train and test dataset according to column \"speaker\".\n",
    "# Be sure to exclude row number, \"speaker\" and response columns from your features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1545466-f4b8-4dac-aedc-23a28aaa34ba",
   "metadata": {},
   "source": [
    "### 2. LDA modelling\n",
    "Fit an LDA model. Compute and report the train and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07740f4-6f7c-4f7f-9186-e808c6a1234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full LDA training score:  0.9440119760479042\n",
      "full LDA training error: ~6%\n",
      "full LDA test score:  0.9195893926432849\n",
      "full LDA test error: ~8.04%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "train_X = train.iloc[:, 0:-1]\n",
    "train_y = train.iloc[:, -1]\n",
    "test_X = test.iloc[:, 0:-1]\n",
    "test_y = test.iloc[:, -1]\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "lda_train_fit = lda.fit_transform(train_X, train_y)\n",
    "lda_test_predictions = lda.predict(test_X)\n",
    "\n",
    "lda_train_predictions = lda.predict(train_X)\n",
    "\n",
    "lda_train_score = lda.score(train_X, train_y)\n",
    "lda_test_score = lda.score(test_X, test_y)\n",
    "print(\"full LDA training score: \", lda_train_score)\n",
    "print(\"full LDA training error: ~\", round(100*(1 - lda_train_score)), \"%\", sep='')\n",
    "print(\"full LDA test score: \", lda_test_score)\n",
    "print(\"full LDA test error: ~\", round(100*(1 - lda_test_score), 2), \"%\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab66f56-297f-4602-aac9-bf6ea03d322a",
   "metadata": {},
   "source": [
    "### 3. LDA canonical coordinates\n",
    " Plot the projection of the training data onto the first two canonical coordinates of the LDA and report your findings. Investigate the data projected on further dimensions using the \\texttt{dimen} parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7100c5d-6304-4720-ac5b-0cba6277b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n",
    "training = plt.scatter(lda_train_predictions, train_y, marker='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2205c6e-02cf-4228-8f81-9396308ba0f7",
   "metadata": {},
   "source": [
    "### 4. LDA on \"aa\", \"ao\"\n",
    "Select the two phonemes \"aa\" and \"ao\". Fit an LDA model on this data set and repeat the steps\n",
    "    done in (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7709f18-b292-4ae3-a13e-d0424e329ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full LDA training score:  0.9440119760479042\n",
      "full LDA training error: ~6%\n",
      "full LDA test score:  0.9195893926432849\n",
      "full LDA test error: ~8.04%\n",
      "aa/ao LDA training score:  0.8935837245696401\n",
      "aa/ao LDA training error: ~11%\n",
      "aa/ao LDA test score:  0.785876993166287\n",
      "aa/ao LDA test error: ~21.41%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_phones = [y for _, y in train.groupby(train['g'])]\n",
    "new_train = pd.DataFrame()\n",
    "new_train = new_train.append(train_phones[0])\n",
    "new_train = new_train.append(train_phones[1])\n",
    "\n",
    "test_phones = [y for _, y in test.groupby(test['g'])]\n",
    "new_test = pd.DataFrame()\n",
    "new_test = new_test.append(test_phones[0])\n",
    "new_test = new_test.append(test_phones[1])\n",
    "\n",
    "new_train_X = new_train.iloc[:, 0:-1]\n",
    "new_train_y = new_train.iloc[:, -1]\n",
    "new_test_X = new_test.iloc[:, 0:-1]\n",
    "new_test_y = new_test.iloc[:, -1]\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "new_lda_train_fit = lda.fit_transform(new_train_X, new_train_y)\n",
    "new_lda_test_predictions = lda.predict(new_test_X)\n",
    "\n",
    "new_lda_train_predictions = lda.predict(new_train_X)\n",
    "\n",
    "new_training = plt.scatter(new_lda_train_predictions, new_train_y, marker='.')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')\n",
    "\n",
    "new_train_score = lda.score(new_train_X, new_train_y)\n",
    "new_test_score = lda.score(new_test_X, new_test_y)\n",
    "\n",
    "print(\"full LDA training score: \", lda_train_score)\n",
    "print(\"full LDA training error: ~\", round(100*(1 - lda_train_score)), \"%\", sep='')\n",
    "print(\"full LDA test score: \", lda_test_score)\n",
    "print(\"full LDA test error: ~\", round(100*(1 - lda_test_score), 2), \"%\", sep='')\n",
    "print(\"aa/ao LDA training score: \", new_train_score)\n",
    "print(\"aa/ao LDA training error: ~\", round(100*(1 - new_train_score)), \"%\", sep='')\n",
    "print(\"aa/ao LDA test score: \", new_test_score)\n",
    "print(\"aa/ao LDA test error: ~\", round(100*(1 - new_test_score), 2), \"%\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b231d3e",
   "metadata": {},
   "source": [
    "## 5. QDA\n",
    "Repeat steps (b) and (d) using QDA and report your findings. Would you prefer LDA or QDA in this example? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52089486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full QDA training score:  1.0\n",
      "full QDA training error: ~0%\n",
      "full QDA test score:  0.8417450812660393\n",
      "full QDA test error: ~16%\n",
      "aa/ao QDA training score:  1.0\n",
      "aa/ao QDA training error: ~0%\n",
      "aa/ao QDA test score:  0.6605922551252847\n",
      "aa/ao QDA test error: ~34%\n",
      "vs\n",
      "full LDA training score:  0.9440119760479042\n",
      "full LDA training error: ~6%\n",
      "full LDA test score:  0.9195893926432849\n",
      "full LDA test error: ~8.04%\n",
      "aa/ao LDA training score:  0.8935837245696401\n",
      "aa/ao LDA training error: ~11%\n",
      "aa/ao LDA test score:  0.785876993166287\n",
      "aa/ao LDA test error: ~21.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "qda = QDA()\n",
    "qda_train_fit = qda.fit(train_X, train_y)\n",
    "qda_test_predictions = qda.predict(test_X)\n",
    "qda_train_score = qda.score(train_X, train_y)\n",
    "qda_test_score = qda.score(test_X, test_y)\n",
    "\n",
    "qda = QDA()\n",
    "new_qda_train_fit = qda.fit(new_train_X, new_train_y)\n",
    "new_qda_test_predictions = qda.predict(new_test_X)\n",
    "new_qda_train_score = qda.score(new_train_X, new_train_y)\n",
    "new_qda_test_score = qda.score(new_test_X, new_test_y)\n",
    "\n",
    "print(\"full QDA training score: \", qda_train_score)\n",
    "print(\"full QDA training error: ~\", round(100*(1 - qda_train_score)), \"%\", sep='')\n",
    "print(\"full QDA test score: \", qda_test_score)\n",
    "print(\"full QDA test error: ~\", round(100*(1 - qda_test_score)), \"%\", sep='')\n",
    "print(\"aa/ao QDA training score: \", new_qda_train_score)\n",
    "print(\"aa/ao QDA training error: ~\", round(100*(1 - new_qda_train_score)), \"%\", sep='')\n",
    "print(\"aa/ao QDA test score: \", new_qda_test_score)\n",
    "print(\"aa/ao QDA test error: ~\", round(100*(1 - new_qda_test_score)), \"%\", sep='')\n",
    "print(\"vs\")\n",
    "print(\"full LDA training score: \", lda_train_score)\n",
    "print(\"full LDA training error: ~\", round(100*(1 - lda_train_score)), \"%\", sep='')\n",
    "print(\"full LDA test score: \", lda_test_score)\n",
    "print(\"full LDA test error: ~\", round(100*(1 - lda_test_score), 2), \"%\", sep='')\n",
    "print(\"aa/ao LDA training score: \", new_train_score)\n",
    "print(\"aa/ao LDA training error: ~\", round(100*(1 - new_train_score)), \"%\", sep='')\n",
    "print(\"aa/ao LDA test score: \", new_test_score)\n",
    "print(\"aa/ao LDA test error: ~\", round(100*(1 - new_test_score), 2), \"%\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9449767",
   "metadata": {},
   "source": [
    "### LDA vs QDA discussion:\n",
    "\n",
    "In both the full array, as well as the reduced aa/ao dataset, QDA outperformed LDA when predicting the training data, and underperformed LDA when predicting the test data. This suggests that QDA overfits, and introduces additional variance, resulting in higher error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d08a3",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices\n",
    "Generate confusion matrices for the LDA and QDA model for \"aa\" and \"ao\". Which differences can you observe between the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA confusion matrix: \n",
      " [[121  55]\n",
      " [ 39 224]]\n",
      "QDA confusion matrix: \n",
      " [[ 29 147]\n",
      " [  2 261]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "true_y = new_test_y\n",
    "lda_predicted_y = new_lda_test_predictions\n",
    "qda_predicted_y = new_qda_test_predictions\n",
    "\n",
    "lda_confusion_matrix = cm(true_y, lda_predicted_y)\n",
    "qda_confusion_matrix = cm(true_y, qda_predicted_y)\n",
    "\n",
    "print(\"LDA confusion matrix: \\n\", lda_confusion_matrix)\n",
    "print(\"QDA confusion matrix: \\n\", qda_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5436fa9",
   "metadata": {},
   "source": [
    "For the LDA model, the false aos are roughly equal to the false aas in number, and proportional to the total ao / aa predictions. The LDA misclassifies roughly 1/4 of both its aa and ao predictions.\n",
    "\n",
    "For the QDA model, the model vastly over-predicts ao, with roughly 1/3 misclassification of ao (and only a small increase in correctly predicted ao), and underpredicts aa, but with lower error (roughly 1/15 misclassification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f56231212a954684e4455fc18e87f1d6f60ff89596aa855e6d309fe16c87e87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
